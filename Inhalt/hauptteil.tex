\chapter{Hauptteil}
* Gliederung in 2 Abschnitte
* Vorarbeit -> Ausarbeiten des bestmöglichen Algorithmus
* Implementierung -> Android App mit Algorithmus

* Verkehrskameras laden
* Verkehrsbilder laden über Verkehrskameras
* Auswahl verschiedener Ansätze
* Vergleich der Ansätze in Bezug auf Ressourcenlast und Effizienz bzw. Effektivität
* Datensätze generieren, um Vergleichskriterien zu erstellen

\section{Verkehrskameras laden}
* SVZ-BW stellt Kamerabilder für verschiedene Kameras zur Verfügung
* Liste von Verkehrskameras laden und verarbeiten % http://www.svz-bw.de/kamera/kamera_A.txt
* Koordinaten in EPSG:25832 gegeben % http://spatialreference.org/ref/epsg/etrs89-utm-zone-32n/
* Übliche Projektion EPSG:4326 % http://spatialreference.org/ref/epsg/wgs-84/
* Umrechnen der Koordinaten in Zielprojektion zur Auswertung der Kamerapositionen

\section{Verkehrsbilder laden}
* Über verarbeitete Kameraliste zugriff auf Verkehrskameras
* Zugriff nur möglich mit korrektem Referrer HTTP-Header (www.svz-bw.de)
* Bilder zu gewünschten Kameras regelmäßig abfragen
* SVZ-BW hat timeout und blockt anfragen nach bestimmter Zeit :(

\section{Vergleichsdatensätze generieren}
* Zur Auswertung der Ansätze sind Vergleichsdaten nötig
* Viele Bilder zu Verschiedenen Verkehrskameras laden
* Verschiedene Tageszeiten verwenden (morgens, mittags, abends, nachts)
* Verschiedene Witterungsverhältnisse einbeziehen sofern möglich (Nebel, Regen, Sonne, ...)
* Auswertung ob Stau oder kein Stau (bzw. Verkehrslage einschätzen)
* Bilder über einen Ansatz Vorkategorisieren und manuell nachbessern

\section{Neuronales Netz}
* Gewählter Ansatz des letzten Jahrgangs
* Vermutlich bester Ansatz, da keine statische Analyse der Bilder durchgeführt wird
	sondern dynamisch auf konkrete Bilder und Verhältnisse (Perspektive und Situation) trainiert wird
* Nicht durchgeführt, da feststand, dass der Ansatz zu Ressourcenintensiv ist und Ziel der Arbeit war Ressourcen zu sparen

\section{Helligkeit}
* Histogramm des Bildes bilden
* Grauwertklassen auswerten
* Anhand von Otsu über Schwellwert Klassifikation des Bildes vornehmen
* Benötigt wenig Ressourcen, aber schlechte Performance weil zugrundeliegende Bilder 
	natürlich sind und Otsu am besten auf binarisierten Bildern arbeitet (schwarz weiß)
	
\section{Haar-Features}
* Erkennen der Autos auf Bildern über Haar-Features und Anschließend zählen, um Stau festzustellen
* OpenCV hat Features für Autos vorgegeben
* Erkennt Autos nicht immer verlässlich
* Arbeitet besser auf Bildreihen (Videos) um Bewegung der speziellen Autos zur verfolgen
* Verkehrskameras liefern über die Zeit zwar viele Bilder, aber mit zu großem zeitlichen Abstand
* Einzelne Autos also nicht verfolgbar
* Schlechte Resultate zur Stauerkennung

\section{Edge detection}
* Erkennen der Kanten über Canny
* Anhand der Kanten Bild Segmentieren und Konturen herausarbeiten zur Erkennung von Merkmalen und Klassifikation
* Auflösung der Kamerabilder zu gering und Bilder recht unscharf mit viel zu Rauschen
* Zu viele Kanten werden erkannt, um Autos verlässlich erkennen zu können
* Mittelung des Bildes über Gauß zeigt keine signifikante Verbesserung aufgrund der zu niedrigen Qualität
	
\section{Background Subtraction}
* Viele Bilder über möglichst kurzen Zeitabstand aufsummieren
* Anhanddessen Hintegrund errechnen
* Hintegrund vom Zielbild abziehen
* Übrig bleiben nur noch Autos
* Morphologische Operatoren zur Nachoptimierung
* Konturen zählen -> Anzahl der Autos
* Über Anzahl der Autos Rückschlüsse über Verkehrssituation ziehen
* Verschiedene BGS algorithmen in OpenCV verfügbar (GSOC, KNN, CNT, GMG, LSBP, MOG, MOG2)
* MOG liefert beste Ergebnisse für konkretes Einsatzgebiet
* Jedoch mehrere Bilder nötig, um Hintergrund verlässlich zu erkennen
* Bei absolutem Stau (keine Bewegung der Autos über längere Zeit ~10min) keine Erkennung des Hintergrundes möglich

\section{Android App}
Blub
